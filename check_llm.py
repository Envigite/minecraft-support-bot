import os
import asyncio
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

load_dotenv()

async def check_ai():
    api_key = os.getenv("OPENAI_API_KEY")
    
    if not api_key:
        print("‚ùå ERROR: No encontr√© la variable OPENAI_API_KEY en el archivo .env")
        return

    print(f"üîë Llave detectada (comienza con): {api_key[:7]}...")
    print("üß† Conectando con GPT-4o-mini (El modelo m√°s econ√≥mico)...")

    try:
        llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
        
        mensaje = [HumanMessage(content="Responde solo con la palabra: FUNCIONANDO")]
        
        respuesta = await llm.ainvoke(mensaje)
        
        print("\nü§ñ Respuesta de la IA:")
        print(f"   '{respuesta.content}'")
        print("\n‚úÖ ¬°CONEXI√ìN EXITOSA! El cerebro est√° listo.")

    except Exception as e:
        print("\n‚ùå ERROR AL CONECTAR CON OPENAI:")
        print(e)
        print("Posibles causas: Saldo insuficiente (cr√©ditos agotados) o llave incorrecta.")

if __name__ == "__main__":
    asyncio.run(check_ai())